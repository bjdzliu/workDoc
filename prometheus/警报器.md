# 警报器

prometheus将警报器分成两部分

- 警报规则(Alerting rules)
- 警报管理器Alertmanager

警报规则运行在prometheus server上,而警报管理器则与prometheus server分开,独立对警报进行管理.

告警由prometheus server产生后,将信号传递给Alertmanager.

设置警报和通知是主要步骤为:

- 安装并配置Alertmanager

- 配置prometheus与Alertmanager通信的参数-alertmanager.url

- 创建警报规则


## Alertmanager

Alertmanager管理客户端发送过来的通知,包括Prometheus server,负责将通知准确得送到接受者那一方.

下面是Alertmanager几个重要概念:

- Grouping:

    Grouping将具有类似属性的警报进行分类,并合并成一个通知.这在大故障触发了成千上万条警报时特别有用.


- Inhibition:

    当具有某种关联的其他警报已经被发出时,Inhibition可以用来抑制后来被触发的警报的发出

- Silences:

    Silences是一种最直截了当的方式能在限定的时间内禁止警报继续发出.它是在web接口上配置的.

- Client behavior:

    Alertmanager也支持客户配置特定的行为.

## Configuration

配置Alertmanager有两种方式,一种是命令行参数,一种是配置文件.

下面之介绍配置文件这一方法:

指定载入的配置文件,alertmanager的配置使用yaml格式编写:

> ./alertmanager -config.file=simple.yml

通用占位符有7个:

- \<duration\>: 匹配正则表达式的间隔 [0-9]+(ms|[smhdwy])
- \<labelname\>: 标签名,可使用正则表达式 [a-zA-Z_][a-zA-Z0-9_]*
- \<labelvalue\>: 标签值
- \<filepath\>: 当前工作目录
- \<boolean\>: 布尔值
- \<string\>: 字符串
- \<tmpl_string\>: 使用模板扩展出来的字符串


配置文件的样例可参考:

    global:
    # The smarthost and SMTP sender used for mail notifications.
    smtp_smarthost: 'localhost:25'
    smtp_from: 'alertmanager@example.org'
    smtp_auth_username: 'alertmanager'
    smtp_auth_password: 'password'
    # The auth token for Hipchat.
    hipchat_auth_token: '1234556789'
    # Alternative host for Hipchat.
    hipchat_url: 'https://hipchat.foobar.org/'

    # The directory from which notification templates are read.
    templates: 
    - '/etc/alertmanager/template/*.tmpl'

    # The root route on which each incoming alert enters.
    route:
    # The labels by which incoming alerts are grouped together. For example,
    # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
    # be batched into a single group.
    group_by: ['alertname', 'cluster', 'service']

    # When a new group of alerts is created by an incoming alert, wait at
    # least 'group_wait' to send the initial notification.
    # This way ensures that you get multiple alerts for the same group that start
    # firing shortly after another are batched together on the first 
    # notification.
    group_wait: 30s

    # When the first notification was sent, wait 'group_interval' to send a batch
    # of new alerts that started firing for that group.
    group_interval: 5m

    # If an alert has successfully been sent, wait 'repeat_interval' to
    # resend them.
    repeat_interval: 3h 

    # A default receiver
    receiver: team-X-mails

    # All the above attributes are inherited by all child routes and can 
    # overwritten on each.

    # The child route trees.
    routes:
    # This routes performs a regular expression match on alert labels to
    # catch alerts that are related to a list of services.
    - match_re:
        service: ^(foo1|foo2|baz)$
        receiver: team-X-mails
        # The service has a sub-route for critical alerts, any alerts
        # that do not match, i.e. severity != critical, fall-back to the
        # parent node and are sent to 'team-X-mails'
        routes:
        - match:
            severity: critical
        receiver: team-X-pager
    - match:
        service: files
        receiver: team-Y-mails

        routes:
        - match:
            severity: critical
        receiver: team-Y-pager

    # This route handles all alerts coming from a database service. If there's
    # no team to handle it, it defaults to the DB team.
    - match:
        service: database
        receiver: team-DB-pager
        # Also group alerts by affected database.
        group_by: [alertname, cluster, database]
        routes:
        - match:
            owner: team-X
        receiver: team-X-pager
        - match:
            owner: team-Y
        receiver: team-Y-pager


    # Inhibition rules allow to mute a set of alerts given that another alert is
    # firing.
    # We use this to mute any warning-level notifications if the same alert is 
    # already critical.
    inhibit_rules:
    - source_match:
        severity: 'critical'
    target_match:
        severity: 'warning'
    # Apply inhibition if the alertname is the same.
    equal: ['alertname', 'cluster', 'service']


    receivers:
    - name: 'team-X-mails'
    email_configs:
    - to: 'team-X+alerts@example.org'

    - name: 'team-X-pager'
    email_configs:
    - to: 'team-X+alerts-critical@example.org'
    pagerduty_configs:
    - service_key: <team-X-key>

    - name: 'team-Y-mails'
    email_configs:
    - to: 'team-Y+alerts@example.org'

    - name: 'team-Y-pager'
    pagerduty_configs:
    - service_key: <team-Y-key>

    - name: 'team-DB-pager'
    pagerduty_configs:
    - service_key: <team-DB-key>
    - name: 'team-X-hipchat'
    hipchat_configs:
    - auth_token: <auth_token>
        room_id: 85
        message_format: html
        notify: true
    Contact GitHub API Training Shop Blog About

# Alerting Rules

警报规则允许你根据PromQL来定义警报的触发条件.

在介绍alerting rules之前先介绍一下recording rules.

prometheus支持两种类型的规则,这些规则可以在一定的周期内被不断得匹配.
两种规则分别是recording rules和alerting rules.

rule文件可以在prometheus运行时通过发送SIGHUP信号进行动态加载.

总得来说,recording rule起的功能就是提供一种预计算的能力,能够提高查询的性能.


语法如下:

> \<new time series name\>[{\<label overrides\>}] = \<expression to record\>

比如:

    # Saving the per-job HTTP in-progress request count as a new set of time series:
    job:http_inprogress_requests:sum = sum(http_inprogress_requests) by (job)

    # Drop or rewrite labels in the result time series:
    new_time_series{label_to_change="new_value",label_to_drop=""} = old_time_series

可以通过evaluation_interval设置recording rules的执行周期.